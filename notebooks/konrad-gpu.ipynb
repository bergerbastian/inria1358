{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38216d69-b181-491d-9af0-4ea2959737e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6be336a-225c-4e14-a35f-ad8b39b892e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f550fda-55e8-4283-803f-b0142ba743ff",
   "metadata": {},
   "source": [
    "# Implementation DeepLab v3+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99701ba7-e1f4-476c-907f-e8fde249e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 09:43:12.049836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 09:43:13.024145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-09-26 09:43:13.024272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-09-26 09:43:13.024283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8da8588-0045-46d3-a437-a8fdbc540da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 09:43:14.771057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:14.786105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:14.788792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:14.791839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 09:43:14.794062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:14.796725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:14.799252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:15.583149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:15.585080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:15.586691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 09:43:15.588218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13582 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_preprocess_data(image_path, mask_path=None):\n",
    "    \"\"\"Function to load images from local storage and preprocess them\n",
    "        Args:\n",
    "            image_path: list of all image paths\n",
    "            mask_path: list of all mask paths (None for tets/predict sets)\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(images=image, size=[512, 512])\n",
    "    image = image/255\n",
    "\n",
    "    # Load and preprocess the mask image\n",
    "    if mask_path is not None:\n",
    "        mask = tf.io.read_file(mask_path)\n",
    "        mask = tf.image.decode_png(mask, channels=1)\n",
    "        mask = tf.image.resize(mask, [512, 512])\n",
    "        mask = tf.math.greater(mask, 127)\n",
    "        mask = tf.cast(mask, tf.float32)        \n",
    "        return image, mask\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def create_datasets(save_path, set=\"train\", test_size=.1, batch_size=64, data_size=1, val_size=.3):\n",
    "    \"\"\"Function to create dataset batches\n",
    "        Args:\n",
    "            save_path: path of images\n",
    "            set: kind of input dataset --> train, test or predict (save_path for predict is end folder)\n",
    "            test_size: size of test_set, ignored for set in [\"predict\", \"test\"] --> float in range (0,1)\n",
    "            batch_size= size of batches --> int\n",
    "            data_size: size of original data to be used --> float in range (0,1), 1 = total data\n",
    "            val_size: size of validation set, ignored for set in [\"predict\", \"test\"] --> float in range (0,1)\n",
    "    \"\"\"\n",
    "    image_dir = f'{save_path}/{set}/images'\n",
    "    mask_dir = f'{save_path}/{set}/gt' if set == \"train\" else None\n",
    "\n",
    "    image_path = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir)]\n",
    "    mask_path = [os.path.join(mask_dir, filename) for filename in os.listdir(mask_dir)] if mask_dir else None\n",
    "    \n",
    "    #test split\n",
    "    image_path_rest, image_path_test, mask_path_rest, mask_path_test = train_test_split(image_path, mask_path, test_size=test_size, random_state=42) if test_size != 0 else (None, None, None, None)\n",
    "\n",
    "    #data size split\n",
    "    image_path_subset, _, mask_path_subset, _ = train_test_split(image_path_rest, mask_path_rest, train_size=data_size) if data_size != 1 else (None, None, None, None)\n",
    "    if data_size == 1:\n",
    "        image_path_subset = image_path_rest\n",
    "        mask_path_subset = mask_path_rest\n",
    "    \n",
    "    #train val split\n",
    "    image_path_train, image_path_val, mask_path_train, mask_path_val = train_test_split(image_path_subset, mask_path_subset, test_size=val_size)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((image_path_train, mask_path_train))\n",
    "    train_dataset = train_dataset.map(load_and_preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    #train_dataset = train_dataset.cache()\n",
    "    #train_dataset = train_dataset.shuffle(1000)\n",
    "    train_batches = train_dataset.batch(batch_size, drop_remainder=True)#.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((image_path_val, mask_path_val))\n",
    "    val_dataset = val_dataset.map(load_and_preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    #val_dataset = val_dataset.cache()\n",
    "    #val_dataset = val_dataset.shuffle(1000)\n",
    "    val_batches = val_dataset.batch(batch_size, drop_remainder=True)#.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # test_dataset = tf.data.Dataset.from_tensor_slices((image_path_test, mask_path_test)) if test_size != 0 else None\n",
    "    # test_dataset = test_dataset.map(load_and_preprocess_data, num_parallel_calls=tf.data.AUTOTUNE) if test_size != 0 else None\n",
    "    # test_batches = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE) if test_size != 0 else None\n",
    "\n",
    "    return train_batches, val_batches\n",
    "\n",
    "train_batches, val_batches = create_datasets(save_path=\"/home/jupyter/bastianberger/inria1358/raw_data/patches2/\", batch_size=2, data_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3719060-55ee-4e4d-b878-7ae4a45b75b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset element_spec=(TensorSpec(shape=(2, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(2, 512, 512, 1), dtype=tf.float32, name=None))>,\n",
       " <BatchDataset element_spec=(TensorSpec(shape=(2, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(2, 512, 512, 1), dtype=tf.float32, name=None))>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches, val_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b139e5fa-3fa3-41ce-9287-beb6065c0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2ad0ea-12d8-4056-9e97-8d2f7c3c2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE, NUM_CLASSES = 512, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b2ef54-d382-4dba-b9c2-f4148c302e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3163cce1-dd8e-4fdb-9395-bac6db871820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatedMeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    def __init__(self,\n",
    "               y_true=None,\n",
    "               y_pred=None,\n",
    "               num_classes=None,\n",
    "               name=None,\n",
    "               dtype=None):\n",
    "        super(UpdatedMeanIoU, self).__init__(num_classes = num_classes,name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "        return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd61384-d126-4a7c-b27a-0e95c2bb3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatedIoU(tf.keras.metrics.IoU):\n",
    "    def __init__(self,\n",
    "               y_true=None,\n",
    "               y_pred=None,\n",
    "                 target_class_ids=None,\n",
    "               num_classes=None,\n",
    "               name=None,\n",
    "               dtype=None):\n",
    "        super(UpdatedIoU, self).__init__(num_classes = num_classes,name=name, dtype=dtype, target_class_ids=target_class_ids)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "        return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f5ca1f-442a-449e-8d26-e2f36e939cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_decay_lr(iteration, maxiter=1000, power=0.9):\n",
    "    \"\"\"Returns the learning rate for the current iteration based on polynomial decay.\"\"\"\n",
    "    base_lr = 1.0  # You can set this to your desired initial learning rate\n",
    "    return base_lr * (1 - (iteration / maxiter)) ** power\n",
    "\n",
    "# 2. Keras learning rate scheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"Returns a learning rate based on epoch number.\"\"\"\n",
    "    iteration = epoch  # if assuming 1 iteration = 1 epoch, adjust as necessary\n",
    "    return polynomial_decay_lr(iteration)\n",
    "\n",
    "# Create a learning rate callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# 3. Apply this scheduler to your optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1.0)  # Set to your initial learning rate\n",
    "\n",
    "# Now, when you fit your model, add the callback:\n",
    "# model.fit(..., callbacks=[lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8f15c2-7761-486a-b197-65d94033515e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "    \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1),\n",
    "    loss=loss,\n",
    "    metrics=[\"accuracy\", UpdatedIoU(num_classes=2, target_class_ids=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165dfdbd-a199-493c-b699-2fd6b8152145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 09:43:55.463978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n",
      "2023-09-26 09:43:59.136337: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f0c3301d700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-26 09:43:59.136383: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-09-26 09:43:59.141868: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-26 09:43:59.292772: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219/3543 [=========>....................] - ETA: 7:09 - loss: 0.6829 - accuracy: 0.8361 - updated_io_u_1: 0.0081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches, validation_data=val_batches, epochs=25, callbacks=[es, lr_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfeeaf6-f53f-4188-b78b-fb405391de00",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a7e07-9033-4570-8f3e-10d2ec47a460",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea46df5a-fc29-4e61-a4af-90d8e3e05cae",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc8d30-516c-4ac6-91ce-82bd20327176",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Saving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9877b08-0bbe-4023-869b-559b75082f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history_unet_point1.history)\n",
    "hist_df.to_csv('./logs/histories/unet_point1.csv')\n",
    "model_unet_point1.save('.logs/models/unet_point1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868cb310-eebf-4f73-abc6-4ee8cabb4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dir = \"/home/jupyter/bastianberger/inria1358/raw_data/patches512/train/gt\"\n",
    "mask_path = [os.path.join(mask_dir, filename) for filename in os.listdir(mask_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1add29ac-9c25-416f-8005-6780e464fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False  True]\n",
      "[False]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Number of labels across all masks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munique_labels_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Maximum number of masks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_label_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m max_label_len\n\u001b[0;32m---> 42\u001b[0m NUM_CLASSES \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_mask_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mcheck_mask_labels\u001b[0;34m(masks)\u001b[0m\n\u001b[1;32m     17\u001b[0m test_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mgreater(test_mask, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#test_mask = tf.cast(test_mask, tf.float32) \u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Find unique labels in the mask\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_labels)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Find the total number of unique labels\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "    \n",
    "# Check labels for all masks\n",
    "def check_mask_labels(masks):\n",
    "    \n",
    "    # Create an empty set\n",
    "    unique_labels_len = set()\n",
    "    \n",
    "    # Iterate over all mask dataset\n",
    "    for mask in masks:\n",
    "        \n",
    "        # Read mask\n",
    "        test_mask = tf.io.read_file(mask)\n",
    "        test_mask = tf.image.decode_png(test_mask, channels=1)\n",
    "        test_mask = tf.image.resize(test_mask, [512, 512])\n",
    "        test_mask = tf.math.greater(test_mask, 0)\n",
    "        #test_mask = tf.cast(test_mask, tf.float32) \n",
    "        \n",
    "        # Find unique labels in the mask\n",
    "        unique_labels = np.unique(test_mask)\n",
    "        print(unique_labels)\n",
    "        \n",
    "        # Find the total number of unique labels\n",
    "        len_unique_labels = len(unique_labels)\n",
    "        \n",
    "        # Add to the set\n",
    "        unique_labels_len.add(len_unique_labels)\n",
    "\n",
    "    # Find the maximum label length\n",
    "    max_label_len = max(unique_labels_len)\n",
    "    \n",
    "    # Convert to list and sort\n",
    "    unique_labels_len = list(unique_labels_len)\n",
    "    unique_labels_len.sort()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\" Number of labels across all masks: {unique_labels_len} \\n Maximum number of masks: {max_label_len}\")\n",
    "\n",
    "    return max_label_len\n",
    "\n",
    "NUM_CLASSES = check_mask_labels(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b532d-557a-4329-9a70-d5a19d9b91b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

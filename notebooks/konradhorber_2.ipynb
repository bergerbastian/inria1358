{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter/bastianberger/inria1358')\n",
    "from ML.data import make_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Checking local data...\u001b[0m\n",
      "0 Patches found for X_train\n",
      "0 Patches found for y_train\n",
      "0 Patches found for X_test\n",
      "❗ Train folders contain 0 images\n",
      "❗ Test folders contain 0 images\n",
      "\u001b[34m\n",
      "Iterating through folder: train/images\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/180 [10:26<2:32:53, 54.28s/it]"
     ]
    }
   ],
   "source": [
    "make_patches(source_path='/home/jupyter/bastianberger/inria1358/raw_data/AerialImageDataset',\n",
    "             save_path='/home/jupyter/bastianberger/inria1358/raw_data/patches500',\n",
    "             image_size=(500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_512(source_path: str, save_path: str, image_size=(200,200), image_type=\"png\", max_files = None):\n",
    "    \"\"\"Function to create patches from the original images, in order to be able to feed them to the model\n",
    "        Args:\n",
    "            source_path: path to the original dataset\n",
    "            save_path: path where the patches should be saved\n",
    "            image_size: (width, height) of patches\n",
    "            image_type: file type that the patches should be outputted in\n",
    "            max_files: maximum number of images to process per subfolder (selected randomly), None = no limit\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking if directories exist, if not, create them\n",
    "    for folder in ['train','test']:\n",
    "        subfolders = ['gt', 'images'] if folder == \"train\" else ['images']\n",
    "        for subfolder in subfolders:\n",
    "            load_path = f'{source_path}/{folder}/{subfolder}'\n",
    "            save_path_n = f'{save_path}/{folder}/{subfolder}'\n",
    "            # Check whether the specified path exists or not\n",
    "            isExist = os.path.exists(save_path_n)\n",
    "            if not isExist:\n",
    "                os.makedirs(save_path_n)\n",
    "\n",
    "    # Checking the local data\n",
    "    sets = []\n",
    "    print(Fore.BLUE + \"\\nChecking local data...\" + Style.RESET_ALL)\n",
    "\n",
    "    # Get # of images from save path\n",
    "    train_images = len(os.listdir(f\"{save_path}/train/images\"))\n",
    "    train_gt = len(os.listdir(f\"{save_path}/train/gt\"))\n",
    "    test_images = len(os.listdir(f\"{save_path}/test/images\"))\n",
    "\n",
    "    print(f\"{train_images} Patches found for X_train\")\n",
    "    print(f\"{train_gt} Patches found for y_train\")\n",
    "    print(f\"{test_images} Patches found for X_test\")\n",
    "\n",
    "    # Check if >0 images are there for each set (meaning we have data) otherwise add it to the sets that we want to patch\n",
    "    if train_images == 0 or train_gt == 0:\n",
    "        print(\"❗ Train folders contain 0 images\")\n",
    "        sets.append(\"train\")\n",
    "    else:\n",
    "        print(\"ℹ️ Train patches already exist\")\n",
    "\n",
    "    if test_images == 0:\n",
    "        print(\"❗ Test folders contain 0 images\")\n",
    "        sets.append(\"test\")\n",
    "    else:\n",
    "        print(\"ℹ️ Test patches already exist\")\n",
    "\n",
    "\n",
    "    # Iterate through the sets\n",
    "    for set in sets:\n",
    "\n",
    "        # Subfolders to iterate through, if the set is train, iterate also iterate through GT folder\n",
    "        subfolders = ['images']\n",
    "        if set == 'train':\n",
    "            subfolders.append('gt')\n",
    "\n",
    "        # Iterate through each subfolder\n",
    "\n",
    "        for subfolder in subfolders:\n",
    "            load_path = f'{source_path}/{set}/{subfolder}'\n",
    "            save_path_n = f'{save_path}/{set}/{subfolder}'\n",
    "\n",
    "            print(Fore.BLUE + f\"\\nIterating through folder: {set}/{subfolder}\" + Style.RESET_ALL)\n",
    "\n",
    "            dimensions = image_size if subfolder == \"gt\" else (image_size[0],image_size[1],3)\n",
    "            file_count = 0\n",
    "\n",
    "            files = os.listdir(load_path)\n",
    "\n",
    "            if max_files is not None:\n",
    "                files = random.sample(files, max_files)\n",
    "\n",
    "            for filename in tqdm(files):\n",
    "                im = Image.open(f'{load_path}/{filename}')\n",
    "                im = im.resize((512,512))\n",
    "                im.save(f'{save_path_n}/{filename}.{image_type}'\n",
    "\n",
    "    # Final Output\n",
    "    # Get # of images from save path\n",
    "    train_images = len(os.listdir(f\"{save_path}/train/images\"))\n",
    "    train_gt = len(os.listdir(f\"{save_path}/train/gt\"))\n",
    "    test_images = len(os.listdir(f\"{save_path}/test/images\"))\n",
    "\n",
    "    if len(sets) > 0:\n",
    "        print(Fore.BLUE + f\"\\nCounting local images...\" + Style.RESET_ALL)\n",
    "        print(f\"{train_images} Patches found for X_train\")\n",
    "        print(f\"{train_gt} Patches found for y_train\")\n",
    "        print(f\"{test_images} Patches found for X_test\")\n",
    "    print(\"✅ Patches loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_512(source_path='/home/jupyter/bastianberger/inria1358/raw_data/patches500',\n",
    "         save_path='/home/jupyter/bastianberger/inria1358/raw_data/patches512')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
